---
title: "Wiki language research"
output: rmarkdown::github_document
---


```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(xml2)
#library(RCurl)
library(curl)
library(RSQLite)
library(httr) # request
library(lubridate) # dates
# geo
library(rnaturalearth)
library(rnaturalearthdata)
library(sf)
```


```{r}
conn <- dbConnect(RSQLite::SQLite(), "wiki_lang.db")
dbDisconnect(conn)
#https://www.datacamp.com/community/tutorials/sqlite-in-r
```

```{r}
response <- GET("https://wikimedia.org/api/rest_v1/metrics/pageviews/aggregate/de.wikipedia.org/all-access/user/monthly/20180901/20180930")

```

```{r}
content(response)$items[[1]]$project
content(response)$items[[1]]$agent
content(response)$items[[1]]$granularity
content(response)$items[[1]]$timestamp
content(response)$items[[1]]$views
```

```{r}
get_total_views <- function(project, site_type, year_month) {
  base_url <- "https://wikimedia.org/api/rest_v1/metrics/pageviews/aggregate"
  
  sart_date <- ymd(str_c(year_month,"-01"))
  end_date <- ymd(str_c(format(sart_date, format="%Y-%m"),"-", days_in_month(sart_date)))
  
  sart_date_str <- format(sart_date, format='%Y%m%d')
  end_date_str <- format(end_date, format='%Y%m%d')
  
  str_glue("{base_url}/{project}/{site_type}/user/monthly/{sart_date_str}/{end_date_str}")
  
}
get_total_views(project = "de.wikipedia.org","mobile-web","2018-01")
```

```{r}
str_c("https://wikimedia.org/api/rest_v1/metrics/pageviews/aggregate/","de.wikipedia.org","/all-access/user/monthly/",20180901,"/",20180930)
```
## project
"de.wikipedia.org"

## site_type
"mobile-web"

```{r}
get_total_views(project = "de.wikipedia.org","mobile-web","2018-01")
```

```{r}
get_total_views(project = "de.wikipedia.org","mobile-web","2018-01") %>% 
  GET() %>% 
  content() %>%  
  #`[[`(1) %>%  `[[`(1)
  pluck(1, 1)
  
```
```{r}
get_total_views(project = "de.wikipedia.org","mobile-web","2018-01") %>% 
  GET() %>% 
  content() %>%  
  pluck(1,1)
  
```
```{r}
gen_months <- function(in_year) {
  1:12 %>%  
  str_pad(width = 2, pad = "0") %>% 
  str_c(in_year,"-",.) # . input reference
}

gen_months(2019)
```
"2015-07" - beginning

## legacy
curl -X GET "https://wikimedia.org/api/rest_v1/metrics/legacy/pagecounts/aggregate/ru.wikipedia.org/all-sites/monthly/2014090100/2014093000" -H "accept: application/json"
"2008-01" - beginning

```{r}
time_data <- function() {
  years <- 2008:2020
  all_years <- c()

  for (y in years) {
    all_years <- c(all_years, gen_months(y))  
  }
  list(
    legacy=all_years[1:which(all_years =="2015-06")],
    new=all_years[which(all_years =="2015-07"):which(all_years =="2020-07")]
  )
}

time_data()
```

### languages to select
https://stats.wikimedia.org/EN/TablesPageViewsMonthlyCombined.htm
https://stats.wikimedia.org/EN/TablesPageViewsMonthlyMobile.htm



```{r}
# returns top 140 languages of wikipedia
get_languages <- function() {
  read_html("https://stats.wikimedia.org/EN/TablesPageViewsMonthlyOriginalCombined.htm") %>%
    xml_find_all("//*[contains(text(),'All&nbsp;languages')][3]") %>% 
    xml_text() %>% 
    str_split(';\nll1') %>% 
    unlist() %>% 
    tail(-1) %>% head(-1) %>% head(140) %>% 
    str_replace_all( "([)']|['()])", "") %>% 
    str_split(',') %>%  
    transpose() %>% lapply(FUN = unlist) %>% 
    map(as_tibble) -> lang_cols
  
  names(lang_cols[[1]])<-"wiki_name"
  names(lang_cols[[2]])<-"language"
  
  bind_cols(lang_cols[[1]],lang_cols[[2]]) %>% 
    mutate(wiki_name=tolower(wiki_name))
}
```

```{r}
language_codes <- get_languages()
language_codes
```


### pageviews/top-by-country

```{r}
response <- GET("https://wikimedia.org/api/rest_v1/metrics/pageviews/top-by-country/ru.wikipedia.org/all-access/2018/09")
```


```{r}
content(response)$items[[1]]$project
content(response)$items[[1]]$access
content(response)$items[[1]]$year
content(response)$items[[1]]$month
content(response)$items[[1]]$project
content(response)$items[[1]]$countries[0:2]
#content(response)
```

"https://wikimedia.org/api/rest_v1/metrics/pageviews/top-by-country/ru.wikipedia.org/all-access/2018/09"

```{r}
get_views_per_country_url <- function(project, site_type, year_month) {
  base_url <- "https://wikimedia.org/api/rest_v1/metrics/pageviews/top-by-country"
  date <- str_split(year_month,"-")
  yr <- date[[1]][1]
  mnth <- date[[1]][2]
  str_glue("{base_url}/{project}/{site_type}/{yr}/{mnth}")
  
}

get_views_per_country_url("ru.wikipedia.org","all-access","2019-08")
```

starts at "2015-05"


```{r}
get_views_per_country_url("ru.wikipedia.org","all-access","2019-08") %>% 
  GET() %>% 
  content() %>% 
  pluck(1,1,"countries") %>%  head(3)
```

```{r}
get_views_per_country_url("ru.wikipedia.org","all-access","2015-05") %>% 
  GET() %>% 
  content() %>% 
  pluck(1,1,"countries") %>%  head(3)
```

old
stats.wikimedia.org/archive/squid_reports/2011-03/SquidReportPageViewsPerCountryBreakdownHuge.htm
stats.wikimedia.org/archive/squid_reports/2012-12/SquidReportPageViewsPerCountryBreakdownHuge.htm
stats.wikimedia.org/archive/squid_reports/2013-09/SquidReportPageViewsPerCountryBreakdownHuge.htm
stats.wikimedia.org/archive/squid_reports/2014-06/SquidReportPageViewsPerCountryBreakdownHuge.htm
stats.wikimedia.org/archive/squid_reports/2014-12/SquidReportPageViewsPerCountryBreakdownHuge.htm
stats.wikimedia.org/archive/squid_reports/2015-01/SquidReportPageViewsPerCountryBreakdownHuge.htm
stats.wikimedia.org/archive/squid_reports/2015-02/SquidReportPageViewsPerCountryBreakdownHuge.htm
stats.wikimedia.org/archive/squid_reports/2015-03/SquidReportPageViewsPerCountryBreakdownHuge.htm
stats.wikimedia.org/archive/squid_reports/2015-04/SquidReportPageViewsPerCountryBreakdownHuge.htm
stats.wikimedia.org/archive/squid_reports/2015-05/SquidReportPageViewsPerCountryBreakdownHuge.htm
stats.wikimedia.org/archive/squid_reports/2015-06/SquidReportPageViewsPerCountryBreakdownHuge.htm
----------


##Map
```{r}
get_views_per_countrie("de.wikipedia.org","all-access","2016-05") %>% 
  GET() %>% 
  content() %>% 
  pluck(1,1,"countries") %>%  
  transpose() %>% 
  lapply(FUN = unlist)  %>% 
  as_tibble() -> de_data

de_data
```

```{r}
get_views_per_country_data <- function(url) {
  GET(url) %>% 
    content() %>% 
    pluck(1,1,"countries") %>%  
    transpose() %>% 
    lapply(FUN = unlist)  %>% 
    as_tibble() %>% 
    select(country,views=views_ceil)
}
  
```


```{r}
get_views_per_country_url("fr.wikipedia.org","all-access","2016-05") %>% 
  get_views_per_country_data()
```


```{r}
get_views_per_country <- function(wiki_lang, site_type, year_month) {
  get_views_per_country_url(str_c(wiki_lang,".wikipedia.org"),"all-access","2016-05") %>% 
    get_views_per_country_data() -> result
  
  result %>% 
    mutate(lang=wiki_lang,type=site_type,date=year_month) %>% 
    select(date,type,lang,country,views)
  
}

get_views_per_country("fr","all-access","2016-05")
```



```{r}
get_total_views(project = "de.wikipedia.org","all-access","2016-05") %>% 
  GET() %>% 
  content() %>%  
  pluck(1, 1 ,'views') -> de_total_views
```



```{r}
de_data %>% 
  select(country,views_ceil) %>% 
  mutate(views_prc=round(views_ceil/de_total_views,3)) -> de_data
# false needs request for every
de_data

```


```{r}
world <- ne_countries(scale = "medium", returnclass = "sf")
```

```{r}
world
```


```{r}
# http://www.statoids.com/wab.html
world$iso_a2
```
```{r}
world %>% 
  left_join(de_data,by = c("iso_a2"="country")) %>% 
  head(10) %>%  
  select(brk_name,views_ceil)
```

```{r fig.height=5, fig.width=8}
# https://www.r-spatial.org/r/2018/10/25/ggplot2-sf.html
# https://dcl-2017-01.github.io/curriculum/notes/spatial-vis.html
# https://datascience.blog.wzb.eu/2019/04/30/zooming-in-on-maps-with-sf-and-ggplot2/
world %>% 
  left_join(de_data,by = c("iso_a2"="country")) %>% 
  ggplot() +
  geom_sf(aes(fill = views_ceil)) +
  scale_fill_viridis_c(option = "plasma", trans = "sqrt") +
  coord_sf(xlim = c(-12, 40), ylim = c(30, 70), expand = T)

```


```{r fig.height=5, fig.width=8}

world %>% 
  left_join(de_data,by = c("iso_a2"="country")) %>% 
  ggplot() +
  geom_sf(aes(fill = views_ceil)) +
  scale_fill_viridis_c(option = "plasma", trans = "sqrt") +
  coord_sf( crs = "+proj=laea")

```

```{r fig.width=8, message=FALSE, warning=FALSE}


world %>% 
  st_crop(xmin = -20, xmax = 45, ymin = 30, ymax = 73) %>% 
  left_join(de_data,by = c("iso_a2"="country")) %>% 
  ggplot() +
  geom_sf(aes(fill = views_ceil)) + theme_bw() +
  scale_fill_viridis_c(option = "plasma", trans = "sqrt") 
  

```

```{r message=FALSE, warning=FALSE}
# read
# https://datascience.blog.wzb.eu/2019/04/30/zooming-in-on-maps-with-sf-and-ggplot2/

target_crs <- '+proj=moll'
disp_win_wgs84 <- st_sfc(st_point(c(-15, 30)), st_point(c(75, 73)), crs = st_crs(4326))
disp_win_trans <- st_transform(disp_win_wgs84, crs = target_crs)
disp_win_coord <- st_coordinates(disp_win_trans)


world %>% 
  st_transform(worldmap, crs = target_crs) %>% 
  left_join(de_data,by = c("iso_a2"="country")) %>% 
  ggplot() +
  geom_sf(aes(fill = views_ceil)) + theme_bw() +
  scale_fill_viridis_c(option = "plasma", trans = "sqrt") +
  coord_sf(xlim = disp_win_coord[,'X'], ylim = disp_win_coord[,'Y'],
             datum = target_crs, expand = FALSE)
```


```{r fig.width=10}
# https://cfss.uchicago.edu/notes/vector-maps/

target_crs <- '+proj=merc'
disp_win_wgs84 <- st_sfc(st_point(c(-23, 30)), st_point(c(47, 71.5)), crs = st_crs(4326))
disp_win_trans <- st_transform(disp_win_wgs84, crs = target_crs)
disp_win_coord <- st_coordinates(disp_win_trans)


world %>% 
  st_transform(worldmap, crs = target_crs) %>% 
  left_join(de_data,by = c("iso_a2"="country")) %>% 
  ggplot() +
  geom_sf(aes(fill = views_ceil)) + theme_bw() +
  scale_fill_viridis_c(option = "plasma", trans = "sqrt") +
  coord_sf(xlim = disp_win_coord[,'X'], ylim = disp_win_coord[,'Y'],
             datum = target_crs, expand = FALSE)

```

http://rstudio-pubs-static.s3.amazonaws.com/467086_decad3a6c9fd44a2a7d9f06c3ae56970.html


## Research
```{r}
query <- "
select p.country,lang,ROUND(views_mobile/mobile_total,3) as prc  FROM
(select country,lang,views_mobile from views_per_country) p
join
(select country,SUM(views_mobile) as mobile_total from views_per_country group by country) t
ON p.country = t.country
where prc > 0.01 order by p.country, prc DESC
"

top_langs <-dbGetQuery(conn, query) %>% as_tibble()
top_langs
```

```{r}

dbGetQuery(conn, "select * from views_per_country") %>% 
  select(country, lang, views_mobile) %>% 
  (function(df) # self reference
    df %>% 
     group_by(country) %>% 
     summarise(mobile_total = sum(views_mobile), .groups = 'drop') %>%
     right_join(df, by=c('country'))
   ) %>% 
  mutate(prc=round(views_mobile/mobile_total,3)) %>% 
  select(country, lang, prc) %>% 
  filter(prc > 0.01) %>% 
  arrange(country, desc(prc))  %>% 
  #####
  filter(country!='--') %>% 
  mutate(country=countrycode(country, 'iso2c','country.name', 
                             custom_match = c('XK' = 'Kosovo'))) %>% 
  left_join(dbGetQuery(conn, "select * from languages"), by = c('lang'='wiki_name')) %>% 
  select(country, language, prc)
  
```



```{r}
library(countrycode)

top_langs %>%
  filter(lang=='ru') %>% 
  filter(country!='--') %>% 
  select(country,prc) %>% 
  mutate(
    country=countrycode(country, 'iso2c','country.name'), 
    cont=countrycode(country, 'country.name','continent')) %>% 
  arrange(desc(prc))
```

```{r}
top_langs %>%
  filter(country=='KP')
```

```{r}
dbGetQuery(conn, "select * from views_per_country where lang=='ru'") %>% 
  select(country,views_total,views_mobile) %>%
  filter(country!='--') %>% 
  mutate(country=countrycode(country, 'iso2c','country.name', 
                             custom_match = c('XK' = 'Kosovo'))) %>% 
  mutate(mprc=round(views_mobile/views_total,3))
  
```

